<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort.min.js"></script>
</head>
<body>
    
    <script>
        // Parse URL parameters
        const urlParams = new URLSearchParams(window.location.search);
        const modelParam = urlParams.get('model') || 'mobilenet';
        
        window.benchmarkState = {
            models: {},
            results: {},
            currentModel: null,
            imageData: [],
            targetModel: modelParam
        };

        // Model configurations
        const MODELS = {
            'base': '/models/trained_model.onnx',
            'mobilenet': '/models/trained_model_mobilenet.onnx', 
            'mobilenetv4': '/models/trained_model_mobilenetv4.onnx'
        };

        // Test images with labels (0 = no, 1 = yes)
        const TEST_IMAGES = [
            { path: '/data/test/no/frame_0_1754078795939.png', label: 0 },
            { path: '/data/test/no/frame_1_1754078795969.png', label: 0 },
            { path: '/data/test/no/frame_10_1754078796252.png', label: 0 },
            { path: '/data/test/no/frame_100_1754078799633.png', label: 0 },
            { path: '/data/test/no/frame_101_1754078799642.png', label: 0 },
            { path: '/data/test/yes/frame_189_1754078801359.png', label: 1 },
            { path: '/data/test/yes/frame_190_1754078801378.png', label: 1 },
            { path: '/data/test/yes/frame_191_1754078801392.png', label: 1 },
            { path: '/data/test/yes/frame_192_1754078801402.png', label: 1 },
            { path: '/data/test/yes/frame_193_1754078801408.png', label: 1 }
        ];

        // Update status
        function updateStatus(message) {
            console.log(message);
        }

        // Load and preprocess image
        async function loadImage(imagePath) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.crossOrigin = 'anonymous';
                
                img.onload = () => {
                    const canvas = document.createElement('canvas');
                    const ctx = canvas.getContext('2d');
                    
                    // Resize to model input size (assuming 224x224)
                    canvas.width = 224;
                    canvas.height = 224;
                    ctx.drawImage(img, 0, 0, 224, 224);
                    
                    const imageData = ctx.getImageData(0, 0, 224, 224);
                    const { data } = imageData;
                    
                    // Convert to Float32Array and normalize (0-1)
                    const inputTensor = new Float32Array(3 * 224 * 224);
                    for (let i = 0; i < data.length; i += 4) {
                        const pixelIndex = i / 4;
                        inputTensor[pixelIndex] = data[i] / 255.0; // R
                        inputTensor[pixelIndex + 224 * 224] = data[i + 1] / 255.0; // G  
                        inputTensor[pixelIndex + 224 * 224 * 2] = data[i + 2] / 255.0; // B
                    }
                    
                    resolve(inputTensor);
                };
                
                img.onerror = reject;
                img.src = imagePath;
            });
        }

        // Run inference on a single image
        async function runInference(session, inputTensor) {
            const startTime = performance.now();
            
            const inputName = session.inputNames[0];
            const feeds = {};
            feeds[inputName] = new ort.Tensor('float32', inputTensor, [1, 3, 224, 224]);
            
            const results = await session.run(feeds);
            const endTime = performance.now();
            
            const outputTensor = results[session.outputNames[0]];
            const prediction = outputTensor.data[0] > 0.5 ? 1 : 0; // Binary classification
            const confidence = outputTensor.data[0];
            
            return {
                prediction,
                confidence,
                latency: endTime - startTime
            };
        }

        // Load a model
        async function loadModel(modelName, modelPath) {
            updateStatus(`Loading model: ${modelName}...`);
            try {
                const session = await ort.InferenceSession.create(modelPath);
                window.benchmarkState.models[modelName] = session;
                updateStatus(`Model ${modelName} loaded successfully`);
                return session;
            } catch (error) {
                updateStatus(`Failed to load model ${modelName}: ${error.message}`);
                throw error;
            }
        }

        // Benchmark a single model
        async function benchmarkModel(modelName) {
            const session = window.benchmarkState.models[modelName];
            if (!session) {
                throw new Error(`Model ${modelName} not loaded`);
            }

            updateStatus(`Benchmarking ${modelName}...`);
            
            const results = {
                modelName,
                totalImages: TEST_IMAGES.length,
                correctPredictions: 0,
                totalLatency: 0,
                predictions: [],
                latencies: []
            };

            for (let i = 0; i < TEST_IMAGES.length; i++) {
                try {
                    updateStatus(`${modelName}: Processing image ${i + 1}/${TEST_IMAGES.length}`);
                    
                    const inputTensor = await loadImage(TEST_IMAGES[i].path);
                    const result = await runInference(session, inputTensor);
                    
                    const isCorrect = result.prediction === TEST_IMAGES[i].label;
                    if (isCorrect) results.correctPredictions++;
                    
                    results.totalLatency += result.latency;
                    results.predictions.push({
                        image: TEST_IMAGES[i].path,
                        prediction: result.prediction,
                        confidence: result.confidence,
                        groundTruth: TEST_IMAGES[i].label,
                        correct: isCorrect,
                        latency: result.latency
                    });
                    results.latencies.push(result.latency);
                    
                } catch (error) {
                    console.error(`Error processing image ${TEST_IMAGES[i].path}:`, error);
                }
            }

            results.accuracy = results.correctPredictions / results.totalImages;
            results.avgLatency = results.totalLatency / results.totalImages;
            results.medianLatency = results.latencies.sort((a, b) => a - b)[Math.floor(results.latencies.length / 2)];
            results.p95Latency = results.latencies[Math.floor(results.latencies.length * 0.95)];

            window.benchmarkState.results[modelName] = results;
            updateStatus(`${modelName} benchmark complete!`);
            
            // Signal completion to Playwright
            window.benchmarkComplete = true;
            
            return results;
        }

        // Initialize and start benchmark
        async function initAndRunBenchmark() {
            try {
                updateStatus('Initializing benchmark...');
                
                const targetModel = window.benchmarkState.targetModel;
                if (!MODELS[targetModel]) {
                    throw new Error(`Unknown model: ${targetModel}`);
                }
                
                // Load only the target model
                await loadModel(targetModel, MODELS[targetModel]);
                
                updateStatus(`Model loaded. Starting benchmark for ${targetModel}...`);
                
                // Run benchmark
                const results = await benchmarkModel(targetModel);
                
                updateStatus('Benchmark complete!');
                console.log('Final results:', results);
                
            } catch (error) {
                updateStatus(`Benchmark failed: ${error.message}`);
                console.error('Benchmark error:', error);
                throw error;
            }
        }

        // Start benchmark when page loads
        window.addEventListener('load', initAndRunBenchmark);
        
        // Expose functions globally for Playwright
        window.benchmarkModel = benchmarkModel;
        window.loadImage = loadImage;
        window.runInference = runInference;
    </script>
</body>
</html>